{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable, grad\n",
    "from pyro.distributions import MultivariateNormal as MVN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class MultivariateNormal in module pyro.distributions.multivariate_normal:\n",
      "\n",
      "class MultivariateNormal(pyro.distributions.distribution.Distribution)\n",
      " |  Multivariate normal (Gaussian) distribution.\n",
      " |  \n",
      " |  A distribution over vectors in which all the elements have a joint Gaussian\n",
      " |  density.\n",
      " |  \n",
      " |  :param torch.autograd.Variable loc: Mean. Must be a vector (Variable\n",
      " |      containing a 1d Tensor).\n",
      " |  :param torch.autograd.Variable covariance_matrix: Covariance matrix.\n",
      " |      Must be symmetric and positive semidefinite.\n",
      " |  :param torch.autograd.Variable scale_tril: The Cholesky decomposition of\n",
      " |      the covariance matrix. You can pass this instead of `covariance_matrix`.\n",
      " |  :param use_inverse_for_batch_log: If this is set to true, the torch.inverse\n",
      " |      function will be used to compute log_pdf. This means that the results of\n",
      " |      log_pdf can be differentiated with respect to the covariance matrix.\n",
      " |      Since the gradient of torch.potri is currently not implemented,\n",
      " |      differentiation of log_pdf wrt. covariance matrix is not possible when\n",
      " |      using the Cholesky decomposition. Using the Cholesky decomposition is\n",
      " |      however much faster and therefore enabled by default.\n",
      " |  :param normalized: If set to `False` the normalization constant is omitted\n",
      " |      in the results of batch_log_pdf and log_pdf. This might be preferable,\n",
      " |      as computing the determinant of the covariance matrix might not always\n",
      " |      be numerically stable. Defaults to `True`.\n",
      " |  :raises: ValueError if the shape of any parameter is not supported.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      MultivariateNormal\n",
      " |      pyro.distributions.distribution.Distribution\n",
      " |      __builtin__.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, loc, covariance_matrix=None, scale_tril=None, batch_size=None, use_inverse_for_batch_log=False, normalized=True, *args, **kwargs)\n",
      " |  \n",
      " |  analytic_mean(self)\n",
      " |      Analytic mean of the distribution, to be implemented by derived classes.\n",
      " |      \n",
      " |      Note that this is optional, and currently only used for testing distributions.\n",
      " |      \n",
      " |      :return: Analytic mean.\n",
      " |      :rtype: torch.autograd.Variable.\n",
      " |      :raises: NotImplementedError if mean cannot be analytically computed.\n",
      " |  \n",
      " |  analytic_var(self)\n",
      " |      Analytic variance of the distribution, to be implemented by derived classes.\n",
      " |      \n",
      " |      Note that this is optional, and currently only used for testing distributions.\n",
      " |      \n",
      " |      :return: Analytic variance.\n",
      " |      :rtype: torch.autograd.Variable.\n",
      " |      :raises: NotImplementedError if variance cannot be analytically computed.\n",
      " |  \n",
      " |  batch_log_pdf(self, x)\n",
      " |      Evaluates log probability densities for each of a batch of samples.\n",
      " |      \n",
      " |      :param torch.autograd.Variable x: A single value or a batch of values\n",
      " |          batched along axis 0.\n",
      " |      :return: log probability densities as a one-dimensional\n",
      " |          `torch.autograd.Variable` with same batch size as value and params.\n",
      " |          The shape of the result should be `self.batch_size()`.\n",
      " |      :rtype: torch.autograd.Variable\n",
      " |  \n",
      " |  batch_shape(self, x=None)\n",
      " |      The left-hand tensor shape of samples, used for batching.\n",
      " |      \n",
      " |      Samples are of shape :code:`d.shape(x) == d.batch_shape(x) + d.event_shape()`.\n",
      " |      \n",
      " |      :param x: Data that is used to determine the batch shape. This is optional. If\n",
      " |          not specified, the distribution parameters are used to determine the shape\n",
      " |          of the batch that is returned from :code:`sample()`.\n",
      " |      :return: Tensor shape used for batching.\n",
      " |      :rtype: torch.Size\n",
      " |      :raises: ValueError if the parameters are not broadcastable to the data shape\n",
      " |  \n",
      " |  event_shape(self)\n",
      " |      The right-hand tensor shape of samples, used for individual events. The\n",
      " |      event dimension(/s) is used to designate random variables that could\n",
      " |      potentially depend on each other, for instance in the case of Dirichlet\n",
      " |      or the OneHotCategorical distribution, but could also simply be used\n",
      " |      for logical grouping, for example in the case of a normal distribution\n",
      " |      with a diagonal covariance matrix.\n",
      " |      \n",
      " |      Samples are of shape `d.shape(x) == d.batch_shape(x) + d.event_shape()`.\n",
      " |      \n",
      " |      :return: Tensor shape used for individual events.\n",
      " |      :rtype: torch.Size\n",
      " |  \n",
      " |  sample(self)\n",
      " |      Generate a sample with the specified covariance matrix and mean.\n",
      " |      \n",
      " |      Differentiation wrt. to the covariance matrix is only supported on\n",
      " |      PyTorch version 0.3.0 or higher.\n",
      " |      Ref: :py:meth:`pyro.distributions.distribution.Distribution.sample`\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset([])\n",
      " |  \n",
      " |  reparameterized = True\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from pyro.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __call__(self, *args, **kwargs)\n",
      " |      Samples a random value (just an alias for `.sample(*args, **kwargs)`).\n",
      " |      \n",
      " |      For tensor distributions, the returned Variable should have the same `.size()` as the\n",
      " |      parameters.\n",
      " |      \n",
      " |      :return: A random value.\n",
      " |      :rtype: torch.autograd.Variable\n",
      " |  \n",
      " |  enumerate_support(self, *args, **kwargs)\n",
      " |      Returns a representation of the parametrized distribution's support.\n",
      " |      \n",
      " |      This is implemented only by discrete distributions.\n",
      " |      \n",
      " |      :return: An iterator over the distribution's discrete support.\n",
      " |      :rtype: iterator\n",
      " |  \n",
      " |  event_dim(self, *args, **kwargs)\n",
      " |      :return: Number of dimensions of individual events.\n",
      " |      :rtype: int\n",
      " |  \n",
      " |  log_pdf(self, x, *args, **kwargs)\n",
      " |      Evaluates total log probability density of a batch of samples.\n",
      " |      \n",
      " |      :param torch.autograd.Variable x: A value.\n",
      " |      :return: total log probability density as a one-dimensional torch.autograd.Variable of size 1.\n",
      " |      :rtype: torch.autograd.Variable\n",
      " |  \n",
      " |  shape(self, x=None, *args, **kwargs)\n",
      " |      The tensor shape of samples from this distribution.\n",
      " |      \n",
      " |      Samples are of shape `d.shape(x) == d.batch_shape(x) + d.event_shape()`.\n",
      " |      \n",
      " |      :return: Tensor shape of samples.\n",
      " |      :rtype: torch.Size\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from pyro.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from pyro.distributions.distribution.Distribution:\n",
      " |  \n",
      " |  enumerable = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(MVN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = Variable(torch.zeros(2))\n",
    "scale_tril = Variable(torch.Tensor([[2, 0], [1, 2]]), requires_grad=True)\n",
    "cov = torch.mm(scale_tril, scale_tril.transpose(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 4  2\n",
       " 2  5\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.9858\n",
       " 1.0031\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = MVN(loc, cov).sample().squeeze()\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.0000\n",
       " 0.9929\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx_dt = torch.Tensor([grad([x[0]], [scale_tril], create_graph=True)[0].data[1, 0],\n",
    "                      grad([x[1]], [scale_tril], create_graph=True)[0].data[1, 0]])\n",
    "dx_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.9929\n",
       " 0.0051\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps = torch.trtrs(x, scale_tril, upper=False)[0][:, 0]\n",
    "eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1.9858\n",
       " 1.0031\n",
       "[torch.FloatTensor of size 2]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mv(scale_tril, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_v(x):\n",
    "    return torch.trtrs(x, scale_tril, upper=False)[0][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
